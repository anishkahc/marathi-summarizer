{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0324 21:08:47.461876 14040 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from collections import Counter\n",
    "\n",
    "import Summarizer\n",
    "import summarizer_data_utils\n",
    "import summarizer_model_utils\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv file using pandas.\n",
    "file_path = './Data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Republican vote dissatisfied by appointing adm...</td>\n",
       "      <td>There is a dissatisfaction in the Republican v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aam Aadmi Party's rebel leader, Shanti Bhushan...</td>\n",
       "      <td>Aam Aadmi Party's rebel leader, Shanti Bhushan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It will take time to get good days - LK Advani...</td>\n",
       "      <td>It will take time to get good days - LK Advani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pak violates ceasefire once again In Poonch di...</td>\n",
       "      <td>Pak violates ceasefire once again In Poonch di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Make Maharashtra four pieces, say ma ga vaida,...</td>\n",
       "      <td>If the Sangh's role is to break Maharashtra, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Republican vote dissatisfied by appointing adm...   \n",
       "1  Aam Aadmi Party's rebel leader, Shanti Bhushan...   \n",
       "2  It will take time to get good days - LK Advani...   \n",
       "3  Pak violates ceasefire once again In Poonch di...   \n",
       "4  Make Maharashtra four pieces, say ma ga vaida,...   \n",
       "\n",
       "                                             Summary  \n",
       "0  There is a dissatisfaction in the Republican v...  \n",
       "1  Aam Aadmi Party's rebel leader, Shanti Bhushan...  \n",
       "2  It will take time to get good days - LK Advani...  \n",
       "3  Pak violates ceasefire once again In Poonch di...  \n",
       "4  If the Sangh's role is to break Maharashtra, t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will not use all of them, only short ones and ones of similar size. \n",
    "# choosing the ones that are of similar length makes it easier for the model to learn.\n",
    "raw_texts = []\n",
    "raw_summaries = []\n",
    "\n",
    "for text, summary in zip(data.Text, data.Summary):\n",
    "    if 100< len(text) < 2000:\n",
    "        raw_texts.append(text)\n",
    "        raw_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_texts), len(raw_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for t, s in zip(raw_texts[:5], raw_summaries[:5]):\n",
    "    #print('Text:\\n', t, '\\n')\n",
    "    #print('Summary:\\n', s, '\\n\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Time:  0.04089164733886719\n"
     ]
    }
   ],
   "source": [
    "# the function gives us the option to keep_most of the characters inisde the texts and summaries, meaning\n",
    "# punctuation, question marks, slashes...\n",
    "# or we can set it to False, meaning we only want to keep letters and numbers like here.\n",
    "processed_texts, processed_summaries, words_counted = summarizer_data_utils.preprocess_texts_and_summaries(\n",
    "    raw_texts,\n",
    "    raw_summaries,\n",
    "    keep_most=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      ": ['republican', 'vote', 'dissatisfied', 'by', 'appointing', 'administrator', 'there', 'is', 'a', 'dissatisfaction', 'in', 'the', 'republican', 'vote', 'of', 'mp', 'ramdas', 'athavale', 'due', 'to', 'the', 'appointment', 'of', 'the', 'state', 'government', 's', 'college', 'in', 'mahad', 'college', 'of', 'people', 's', 'education', 'society', 'of', 'babasaheb', 'ambedkar', 'the', 'republican', 'bahujan', 'vidyarthi', 'parishad', 'has', 'protested', 'against', 'the', 'government', 's', 'decision', 'and', 'the', 'state', 'government', 'will', 'have', 'to', 'face', 'its', 'protest', 'dr', 'people', 'from', 'pune', 's', 'education', 'society', 'founded', 'by', 'dr', 'babasaheb', 'ambedkar', 'are', 'from', 'mahad', 'pune', 'aurangabad', 'marathwada', 'konkan', 'and', 'many', 'places', 'in', 'bangalore', 'the', 'office', 'of', 'ambedkar', 'and', 'siddhartha', 'college', 'has', 'its', 'office', 'in', 'mumbai', 'the', 'issue', 'has', 'been', 'going', 'on', 'for', 'a', 'number', 'of', 'years', 'as', 'the', 'board', 'of', 'directors', 'of', 'the', 'organization', 'and', 'the', 'matter', 'has', 'reached', 'the', 'high', 'court', 'various', 'organizations', 'have', 'been', 'closed', 'due', 'to', 'the', 'overwhelming', 'influence', 'of', 'the', 'existing', 'board', 'of', 'directors', 'although', 'the', 'ugc', 'the', 'university', 'of', 'mumbai', 'and', 'the', 'education', 'department', 'often', 'issued', 'notices', 'to', 'the', 'management', 'it', 'did', 'not', 'matter', 'only', 'dr', 'no', 'government', 'has', 'shown', 'the', 'courage', 'to', 'take', 'action', 'till', 'now', 'by', 'babasaheb', 'ambedkar', 'dr', 'mahad', 'in', 'the', 'babasaheb', 'ambedkar', 'college', 'for', 'several', 'days', 'there', 'was', 'a', 'dispute', 'between', 'the', 'principal', 'as', 'a', 'result', 'of', 'the', 'many', 'irregularities', 'on', '1', 'april', '2016', 'the', 'director', 'of', 'education', 'appointed', 'the', 'post', 'of', 'sub', 'divisional', 'officer', 'sushma', 'satpute', 'as', 'administrator'] \n",
      "\n",
      "Summary:\n",
      " ['there', 'is', 'a', 'dissatisfaction', 'in', 'the', 'republican', 'vote', 'of', 'mp', 'ramdas', 'athavale', 'due', 'to', 'the', 'appointment', 'of', 'the', 'state', 'government', 's', 'college', 'in', 'mahad', 'college', 'of', 'people', 's', 'education', 'society', 'of', 'babasaheb', 'ambedkar', 'the', 'republican', 'bahujan', 'vidyarthi', 'parishad', 'has', 'protested', 'against', 'the', 'government', 's', 'decision', 'and', 'the', 'state', 'government', 'will', 'have', 'to', 'face', 'its', 'protest', 'people', 'from', 'pune', 's', 'education', 'society', 'founded', 'by', 'dr', 'babasaheb', 'ambedkar', 'are', 'from', 'mahad', 'pune', 'aurangabad', 'marathwada', 'konkan', 'and', 'many', 'places', 'in', 'bangalore', 'no', 'government', 'has', 'shown', 'the', 'courage', 'to', 'take', 'action', 'till', 'now', 'by', 'babasaheb', 'ambedkar', 'in', 'the', 'babasaheb', 'ambedkar', 'college', 'for', 'several', 'days', 'there', 'was', 'a', 'dispute', 'between', 'the', 'principal'] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t,s in zip(processed_texts[:1], processed_summaries[:1]):\n",
    "    print('Text\\n:', t, '\\n')\n",
    "    print('Summary:\\n', s, '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 354 0\n"
     ]
    }
   ],
   "source": [
    "# create lookup dicts.\n",
    "# most oft the words only appear only once. \n",
    "specials = [\"<EOS>\", \"<SOS>\",\"<PAD>\",\"<UNK>\"]\n",
    "word2ind, ind2word,  missing_words = summarizer_data_utils.create_word_inds_dicts(words_counted,\n",
    "                                                                       specials = specials)\n",
    "print(len(word2ind), len(ind2word), len(missing_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0324 21:08:51.105129 14040 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# the embeddings from tf.hub. \n",
    "# embed = hub.Module(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
    "embed = hub.Module(\"https://tfhub.dev/google/Wiki-words-250/1\")\n",
    "emb = embed([key for key in word2ind.keys()])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    embedding = sess.run(emb)\n",
    "\n",
    "#glove_embeddings_path = './glove/glove.42B.300d.txt'\n",
    "#embedding_matrix_save_path = './embeddings/my_embedding.npy'\n",
    "#emb = summarizer_data_utils.create_and_save_embedding_matrix(word2ind,\n",
    "#                                                       glove_embeddings_path,\n",
    "#                                                       embedding_matrix_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 250)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./tf_hub_embedding_headlines.npy', embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts words in texts and summaries to indices\n",
    "# it looks like we have to set eos here to False\n",
    "converted_texts, unknown_words_in_texts = summarizer_data_utils.convert_to_inds(processed_texts,\n",
    "                                                                                word2ind,\n",
    "                                                                                eos = False)\n",
    "\n",
    "converted_summaries, unknown_words_in_summaries = summarizer_data_utils.convert_to_inds(processed_summaries,\n",
    "                                                                                        word2ind,\n",
    "                                                                                        eos = True,\n",
    "                                                                                        sos = True)\n",
    "\n",
    "#converted_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['republican', 'vote', 'dissatisfied', 'by', 'appointing', 'administrator', 'there', 'is', 'a', 'dissatisfaction', 'in', 'the', 'republican', 'vote', 'of', 'mp', 'ramdas', 'athavale', 'due', 'to', 'the', 'appointment', 'of', 'the', 'state', 'government', 's', 'college', 'in', 'mahad', 'college', 'of', 'people', 's', 'education', 'society', 'of', 'babasaheb', 'ambedkar', 'the', 'republican', 'bahujan', 'vidyarthi', 'parishad', 'has', 'protested', 'against', 'the', 'government', 's', 'decision', 'and', 'the', 'state', 'government', 'will', 'have', 'to', 'face', 'its', 'protest', 'dr', 'people', 'from', 'pune', 's', 'education', 'society', 'founded', 'by', 'dr', 'babasaheb', 'ambedkar', 'are', 'from', 'mahad', 'pune', 'aurangabad', 'marathwada', 'konkan', 'and', 'many', 'places', 'in', 'bangalore', 'the', 'office', 'of', 'ambedkar', 'and', 'siddhartha', 'college', 'has', 'its', 'office', 'in', 'mumbai', 'the', 'issue', 'has', 'been', 'going', 'on', 'for', 'a', 'number', 'of', 'years', 'as', 'the', 'board', 'of', 'directors', 'of', 'the', 'organization', 'and', 'the', 'matter', 'has', 'reached', 'the', 'high', 'court', 'various', 'organizations', 'have', 'been', 'closed', 'due', 'to', 'the', 'overwhelming', 'influence', 'of', 'the', 'existing', 'board', 'of', 'directors', 'although', 'the', 'ugc', 'the', 'university', 'of', 'mumbai', 'and', 'the', 'education', 'department', 'often', 'issued', 'notices', 'to', 'the', 'management', 'it', 'did', 'not', 'matter', 'only', 'dr', 'no', 'government', 'has', 'shown', 'the', 'courage', 'to', 'take', 'action', 'till', 'now', 'by', 'babasaheb', 'ambedkar', 'dr', 'mahad', 'in', 'the', 'babasaheb', 'ambedkar', 'college', 'for', 'several', 'days', 'there', 'was', 'a', 'dispute', 'between', 'the', 'principal', 'as', 'a', 'result', 'of', 'the', 'many', 'irregularities', 'on', '1', 'april', '2016', 'the', 'director', 'of', 'education', 'appointed', 'the', 'post', 'of', 'sub', 'divisional', 'officer', 'sushma', 'satpute', 'as', 'administrator'] ['<SOS>', 'there', 'is', 'a', 'dissatisfaction', 'in', 'the', 'republican', 'vote', 'of', 'mp', 'ramdas', 'athavale', 'due', 'to', 'the', 'appointment', 'of', 'the', 'state', 'government', 's', 'college', 'in', 'mahad', 'college', 'of', 'people', 's', 'education', 'society', 'of', 'babasaheb', 'ambedkar', 'the', 'republican', 'bahujan', 'vidyarthi', 'parishad', 'has', 'protested', 'against', 'the', 'government', 's', 'decision', 'and', 'the', 'state', 'government', 'will', 'have', 'to', 'face', 'its', 'protest', 'people', 'from', 'pune', 's', 'education', 'society', 'founded', 'by', 'dr', 'babasaheb', 'ambedkar', 'are', 'from', 'mahad', 'pune', 'aurangabad', 'marathwada', 'konkan', 'and', 'many', 'places', 'in', 'bangalore', 'no', 'government', 'has', 'shown', 'the', 'courage', 'to', 'take', 'action', 'till', 'now', 'by', 'babasaheb', 'ambedkar', 'in', 'the', 'babasaheb', 'ambedkar', 'college', 'for', 'several', 'days', 'there', 'was', 'a', 'dispute', 'between', 'the', 'principal', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "# seems to have worked well. \n",
    "print( summarizer_data_utils.convert_inds_to_text(converted_texts[0], ind2word),\n",
    "       summarizer_data_utils.convert_inds_to_text(converted_summaries[0], ind2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "num_layers_encoder = 4\n",
    "num_layers_decoder = 4\n",
    "rnn_size_encoder = 250\n",
    "rnn_size_decoder = 250\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 2\n",
    "clip = 2\n",
    "keep_probability = 0.8\n",
    "learning_rate = 0.0005\n",
    "max_lr=0.005\n",
    "learning_rate_decay_steps = 100\n",
    "learning_rate_decay = 0.90\n",
    "\n",
    "\n",
    "pretrained_embeddings_path = './tf_hub_embedding_headlines.npy'\n",
    "summary_dir = os.path.join('./tensorboard/headlines')\n",
    "\n",
    "use_cyclic_lr = True\n",
    "inference_targets=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(converted_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained embeddings.\n",
      "WARNING:tensorflow:From D:\\Softwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0324 21:09:03.450108 14040 tf_logging.py:125] From D:\\Softwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Softwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0324 21:09:03.486014 14040 tf_logging.py:125] From D:\\Softwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "D:\\Softwares\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph built.\n",
      "-------------------- Epoch 0 of 2 --------------------\n",
      "Iteration: 0 of 0\ttrain_loss: 5.8692\n",
      "Average Score for this Epoch: 5.869154930114746\n",
      "--- new best score ---\n",
      "\n",
      "\n",
      "-------------------- Epoch 1 of 2 --------------------\n",
      "Iteration: 0 of 0\ttrain_loss: 5.8610\n",
      "Average Score for this Epoch: 5.861011028289795\n",
      "--- new best score ---\n",
      "\n",
      "\n",
      "-------------------- Epoch 2 of 2 --------------------\n",
      "Iteration: 0 of 0\ttrain_loss: 5.8414\n",
      "Average Score for this Epoch: 5.841433048248291\n",
      "--- new best score ---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build graph and train the model \n",
    "summarizer_model_utils.reset_graph()\n",
    "summarizer = Summarizer.Summarizer(word2ind,\n",
    "                                   ind2word,\n",
    "                                   save_path='./models/headlines/my_model',\n",
    "                                   mode='TRAIN',\n",
    "                                   num_layers_encoder = num_layers_encoder,\n",
    "                                   num_layers_decoder = num_layers_decoder,\n",
    "                                   rnn_size_encoder = rnn_size_encoder,\n",
    "                                   rnn_size_decoder = rnn_size_decoder,\n",
    "                                   batch_size = batch_size,\n",
    "                                   clip = clip,\n",
    "                                   keep_probability = keep_probability,\n",
    "                                   learning_rate = learning_rate,\n",
    "                                   max_lr=max_lr,\n",
    "                                   learning_rate_decay_steps = learning_rate_decay_steps,\n",
    "                                   learning_rate_decay = learning_rate_decay,\n",
    "                                   epochs = epochs,\n",
    "                                   pretrained_embeddings_path = pretrained_embeddings_path,\n",
    "                                   use_cyclic_lr = use_cyclic_lr,)\n",
    "#                                    summary_dir = summary_dir)           \n",
    "\n",
    "summarizer.build_graph()\n",
    "summarizer.train(converted_texts, \n",
    "                 converted_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained embeddings.\n",
      "Graph built.\n",
      "INFO:tensorflow:Restoring parameters from ./models/headlines/my_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0324 21:05:33.629667  1644 tf_logging.py:115] Restoring parameters from ./models/headlines/my_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path Restored.\n",
      "if executed\n"
     ]
    }
   ],
   "source": [
    "summarizer_model_utils.reset_graph()\n",
    "summarizer = Summarizer.Summarizer(word2ind,\n",
    "                                   ind2word,\n",
    "                                   './models/headlines/my_model',\n",
    "                                   'INFER',\n",
    "                                   num_layers_encoder = num_layers_encoder,\n",
    "                                   num_layers_decoder = num_layers_decoder,\n",
    "                                   batch_size = len(converted_texts[:5]),\n",
    "                                   clip = clip,\n",
    "                                   keep_probability = 1.0,\n",
    "                                   learning_rate = 0.0,\n",
    "                                   beam_width = 5,\n",
    "                                   rnn_size_encoder = rnn_size_encoder,\n",
    "                                   rnn_size_decoder = rnn_size_decoder,\n",
    "                                   inference_targets = False,\n",
    "                                   pretrained_embeddings_path = pretrained_embeddings_path)\n",
    "\n",
    "summarizer.build_graph()\n",
    "preds = summarizer.infer(inputs = converted_texts[:5],\n",
    "                         restore_path =  './models/headlines/my_model',\n",
    "                         targets = converted_summaries[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a4ee8507e0c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# show results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m summarizer_model_utils.sample_results(preds,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                       \u001b[0mind2word\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                       \u001b[0mword2ind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                       \u001b[0mconverted_summaries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "# show results\n",
    "summarizer_model_utils.sample_results(preds,\n",
    "                                      ind2word,\n",
    "                                      word2ind,\n",
    "                                      converted_summaries[:5],\n",
    "                                      converted_texts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
